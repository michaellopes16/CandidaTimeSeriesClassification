{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9f2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime==0.11.3 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (0.13.2)\n",
      "Requirement already satisfied: numba>=0.53 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (0.55.1)\n",
      "Requirement already satisfied: scipy<1.9.0 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (1.7.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (1.2.13)\n",
      "Requirement already satisfied: numpy<1.22,>=1.21.0 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (1.21.5)\n",
      "Requirement already satisfied: pandas<1.5.0,>=1.1.0 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from sktime==0.11.3) (1.4.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from deprecated>=1.2.13->sktime==0.11.3) (1.13.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from numba>=0.53->sktime==0.11.3) (0.38.0)\n",
      "Requirement already satisfied: setuptools in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from numba>=0.53->sktime==0.11.3) (58.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from pandas<1.5.0,>=1.1.0->sktime==0.11.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from pandas<1.5.0,>=1.1.0->sktime==0.11.3) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<1.5.0,>=1.1.0->sktime==0.11.3) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from scikit-learn>=0.24.0->sktime==0.11.3) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from scikit-learn>=0.24.0->sktime==0.11.3) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from statsmodels>=0.12.1->sktime==0.11.3) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from statsmodels>=0.12.1->sktime==0.11.3) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\pessoais\\anacondafiles\\envs\\teste_with_gpu\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.12.1->sktime==0.11.3) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sktime==0.11.3\n",
    "#%pip install numpy=1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3022fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import tensorflow as tf\n",
    "from pickle import dump\n",
    "\n",
    "from sktime.classification.distance_based import ElasticEnsemble\n",
    "from sktime._contrib.vector_classifiers._rotation_forest import RotationForest\n",
    "from sktime.datasets import load_from_arff_to_dataframe as load_arff\n",
    "#numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58bb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b5e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a99c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12256, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "X, y = load_arff(\"AllCandidas_TRAIN_V2.arff\")\n",
    "print(np.shape(X))\n",
    "print(type(X))\n",
    "precision = []\n",
    "accuracy = []\n",
    "f1 = []\n",
    "recall = []\n",
    "def gpu(X, y, kf):\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    i= 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #print(X_train.head())\n",
    "        #print(type(X_train))\n",
    "        print(\"Treining EE...\")\n",
    "        EE =     ElasticEnsemble(\n",
    "        proportion_of_param_options=0.1,\n",
    "        proportion_train_for_test=0.1,\n",
    "    )\n",
    "        print(f\"Interaction {i}\")\n",
    "        print(\"In trainning...\")\n",
    "        EE.fit(X_train, y_train)\n",
    "        print(\"In prediction...\")\n",
    "        i=i+1\n",
    "        \n",
    "        # Predict and print accuracy\n",
    "        predictions = EE.predict(X_test)\n",
    "        precision.append(precision_score(y_test, predictions, average='macro',zero_division=1))\n",
    "        accuracy.append(accuracy_score(y_test, predictions))\n",
    "        recall.append(recall_score(y_test, predictions, average='macro',zero_division=1))\n",
    "        f1.append(f1_score(y_test, predictions, average='macro'))\n",
    "        #print(\"In prediction...\")\n",
    "        # Predict and print accuracy\n",
    "       # predictions = HC2.predict(X_test)\n",
    "    print(type(X_train))\n",
    "    print(np.shape(X_train))\n",
    "    print(f\"Precision: {np.mean(precision)}, Accuracy:{np.mean(accuracy)}, Recall: {np.mean(recall)}, F1: {np.mean(f1)}\")\n",
    "    return np.mean(precision), np.mean(accuracy), np.mean(recall), np.mean(f1), np.std(accuracy), EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27233012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MirroredStrategy\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "MirroredVariable:{\n",
      "  0: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
      "}\n",
      "Treining EE...\n",
      "Interaction 0\n",
      "In trainning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 482, in save\n",
      "    data_name = overloads[key]\n",
      "KeyError: ((array(float64, 2d, C), array(float64, 2d, C)), ('x86_64-pc-windows-msvc', 'skylake', '+64bit,+adx,+aes,-amx-bf16,-amx-int8,-amx-tile,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vp2intersect,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,-rtm,+sahf,-serialize,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-tsxldtrk,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('1d3d7e2fe55cfe8ed77fd729ec86555dd1de468698149a4dfe88d16522f9a064', 'c22968cf64fe78712d3aec1ed38308bbf69789c9c772817214ab399fe25acb1c'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sktime\\classification\\distance_based\\_time_series_neighbors.py\", line 314, in predict\n",
      "    return BaseClassifier.predict(self, X, **kwargs)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sktime\\classification\\base.py\", line 202, in predict\n",
      "    return self._predict(X)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sktime\\classification\\distance_based\\_time_series_neighbors.py\", line 338, in _predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sktime\\classification\\distance_based\\_time_series_neighbors.py\", line 280, in kneighbors\n",
      "    dist, neigh_ind = zip(*result)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1717, in pairwise_distances_chunked\n",
      "    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1889, in pairwise_distances\n",
      "    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1430, in _parallel_pairwise\n",
      "    return func(X, Y, **kwds)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1474, in _pairwise_callable\n",
      "    out[i, j] = metric(X[i], Y[j], **kwds)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 487, in _compile_for_args\n",
      "    raise e\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 420, in _compile_for_args\n",
      "    return_val = self.compile(tuple(argtypes))\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 972, in compile\n",
      "    self._cache.save_overload(sig, cres)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 664, in save_overload\n",
      "    self._save_overload(sig, data)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 674, in _save_overload\n",
      "    self._cache_file.save(key, data)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 491, in save\n",
      "    self._save_index(overloads)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 535, in _save_index\n",
      "    data = self._dump(data)\n",
      "  File \"D:\\Pessoais\\AnacondaFiles\\envs\\teste_with_gpu\\lib\\site-packages\\numba\\core\\caching.py\", line 563, in _dump\n",
      "    return pickle.dumps(obj, protocol=-1)\n",
      "MemoryError\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"Using MirroredStrategy\")\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "else:  # Use the Default Strategy\n",
    "  print(\"Using Default Strategy\")\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with strategy.scope():\n",
    "  # Do something interesting\n",
    "  print(tf.Variable(1.))\n",
    "  precision, accuracy, recall, f1, std, EE = gpu(X,y,kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall','f1_score','std'])\n",
    "df_metrics['precision'] = precision\n",
    "df_metrics['accuracy'] = accuracy\n",
    "df_metrics['recall'] = recall\n",
    "df_metrics['f1_score'] = f1\n",
    "df_metrics['std'] = std\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save metrics\n",
    "print(\"Saving metrics...\")\n",
    "df_metrics.to_csv(\"results/\" + 'df_metrics_EE.csv', index=False)\n",
    "#save the model\n",
    "print(\"Saving model...\")\n",
    "dump(EE, open('results/'+'EE_model.pkl', 'wb'))\n",
    "print(\"Metrics of model:\")\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlb\\AppData\\Local\\Temp/ipykernel_30112/1082374303.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "(19999, 1)\n",
      "(19999,)\n",
      "Treining EE...\n",
      "In prediction...\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    res = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                       columns=['precision', 'accuracy', 'recall','f1_score'])\n",
    "    X_train, y_train = load_arff(\"AllCandidasCollectReduced.arff\")\n",
    "    #X_test, y_test = load_arff(\"AllCandidas_TEST_2.arff\")\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "    precision = make_scorer(precision_score, average='weighted',zero_division=1)\n",
    "    recall = make_scorer(recall_score, average='weighted',zero_division=1)\n",
    "    print(type(X_train))\n",
    "    print(type(y_train))\n",
    "    print(np.shape(X_train))\n",
    "    print(np.shape(y_train))\n",
    "    # Fit HC2\n",
    "    print(\"Treining EE...\")\n",
    "    EE =     ElasticEnsemble(\n",
    "    proportion_of_param_options=0.1,\n",
    "    proportion_train_for_test=0.1,\n",
    ")\n",
    "    print(\"In prediction...\")\n",
    "    res['precision'] = cross_val_score(EE, X_train, y_train, cv=cv,scoring=precision).mean()\n",
    "    print(f\"Precision result: {res['precision'][0]}\")\n",
    "    res['accuracy'] = cross_val_score(EE, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
    "    print(f\"Accuracy result: {res['accuracy'][0]}\")\n",
    "    res['recall'] = cross_val_score(EE, X_train, y_train, cv=cv,scoring=recall).mean()\n",
    "    print(f\"Recall result: {res['recall'][0]}\")\n",
    "    res['f1_score'] = cross_val_score(EE, X_train, y_train, cv=cv,scoring='f1_weighted').mean()\n",
    "    print(f\"F1_score result: {res['f1_score'][0]}\")\n",
    "    return res , EE\n",
    "df_metrics, EE_model = gpu()\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save metrics\n",
    "print(\"Saving metrics...\")\n",
    "df_metrics.to_csv('results/'+ 'df_metrics_EE.csv', index=False)\n",
    "#save the model\n",
    "print(\"Saving model...\")\n",
    "dump(EE_model, open('results/'+'EE_model.pkl', 'wb'))\n",
    "print(\"Metrics of model:\")\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9dae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748420fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
